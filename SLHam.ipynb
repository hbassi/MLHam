{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b284159-7f80-4d9f-90e7-975fba6066ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, lax, vmap, jacobian\n",
    "import jax.scipy.linalg as jsl\n",
    "\n",
    "import jax\n",
    "\n",
    "import numpy as np\n",
    "from read_traj_v2 import *\n",
    "\n",
    "import scipy.optimize\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79a0da5f-028b-4f4c-be12-7ca07585cabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torch\n",
      "  Downloading torch-2.0.0-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.15.1-cp39-cp39-manylinux1_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m131.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading torchaudio-2.0.1-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m217.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from torch) (4.2.0)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m165.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from torch) (3.7.1)\n",
      "Requirement already satisfied: jinja2 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Collecting triton==2.0.0\n",
      "  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m137.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (61.2.0)\n",
      "Collecting cmake\n",
      "  Downloading cmake-3.26.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lit\n",
      "  Downloading lit-16.0.2.tar.gz (137 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from torchvision) (1.22.4)\n",
      "Requirement already satisfied: requests in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from torchvision) (9.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from requests->torchvision) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages (from requests->torchvision) (2022.5.18.1)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: lit\n",
      "  Building wheel for lit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-16.0.2-py3-none-any.whl size=88194 sha256=9637c5140122ac9b75f6e981eb4af7e2232997f5580f8c6452978a31ebbb6c0b\n",
      "  Stored in directory: /global/u1/h/hbassi/.cache/pip/wheels/bf/a0/7c/a850abc2cfad92656c1bc61795c340ce1f741c1686ad9f0908\n",
      "Successfully built lit\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for tabulate: [Errno 2] No such file or directory: '/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/tabulate-0.8.10.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: mpmath, lit, cmake, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, networkx, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision, torchaudio\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed cmake-3.26.3 lit-16.0.2 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 sympy-1.11.1 torch-2.0.0 torchaudio-2.0.1 torchvision-0.15.1 triton-2.0.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ax (/global/u1/h/hbassi/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/bin/python -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f652cf0-1006-4ab2-9b0e-3b18176f72ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d65dfd65-0527-4b63-9fd6-1d1e188f0c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\treading from \"./correctdata/ke+en+overlap+ee_twoe+dip_casscf22_heh+_sto-3g.npz\"\n",
      "\n",
      "can only concatenate str (not \"NoneType\") to str\n",
      "True is not in list\n"
     ]
    }
   ],
   "source": [
    "mol = 'heh+'\n",
    "basis = 'sto-3g'\n",
    "init = 'hf'\n",
    "td = 'rt-tdexx'\n",
    "\n",
    "dt = 0.08268/10\n",
    "\n",
    "inpath = './correctdata'\n",
    "inpath2 = './mydata/'\n",
    "outpath = './'\n",
    "saved_model_dir = './models/'\n",
    "\n",
    "trnfrq = jnp.array(np.load('./tdcis_data/tdcis_trnfreq_dt0.008268.npz'))\n",
    "trnamp = jnp.array(np.load('./tdcis_data/tdcis_trnamp_dt0.008268.npz'))\n",
    "trntme = jnp.array(np.load('./tdcis_data/tdcis_trntme_dt0.008268.npz'))\n",
    "# load important static matrices\n",
    "a = traj_data(inpath, mol, basis, init, td, '001',\n",
    "                init_cond_file=f'ke+en+overlap+ee_twoe+dip_casscf22_{mol}_{basis}.npz',\n",
    "                )\n",
    "a.assign_init_data()\n",
    "drc = a.drc\n",
    "xmat, didat, kinmat, enmat = a.xmat, a.didat, a.kinmat, a.enmat\n",
    "X = xmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eac6183-de7c-4322-ae9b-e928ee129e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301, 10000, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "trnden = np.array(np.load('./tdcis_data/tdcis_dt0.0082680.npz'))\n",
    "print(trnden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "871387af-8a1e-431c-a25e-657f12b6e36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 10000, 2)\n"
     ]
    }
   ],
   "source": [
    "trntimecoeffs = np.array(np.load('./tdcis_data/time_coeffs_tdcis_dt0.008268.npz'))\n",
    "print(trntimecoeffs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8d7e342a-c268-421c-ab11-cde905996c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "input_size = 4\n",
    "output_size = 2\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    \n",
    "        # layer 1\n",
    "        self.fc1 = nn.Linear(input_size, 100) \n",
    "        self.batch1 = nn.BatchNorm1d(100)\n",
    "        self.drop1 = nn.Dropout(0.25)\n",
    "\n",
    "        # layer 2\n",
    "        self.fc2 = nn.Linear(100, 80)\n",
    "        self.batch2 = nn.BatchNorm1d(80)\n",
    "        self.drop2 = nn.Dropout(0.25)\n",
    "\n",
    "        # layer 3\n",
    "        self.fc3 = nn.Linear(80, 60)\n",
    "        self.batch3 = nn.BatchNorm1d(60)\n",
    "        self.drop3 = nn.Dropout(0.25)\n",
    "\n",
    "        # layer 4\n",
    "        self.fc4 = nn.Linear(60, 40)\n",
    "        self.batch4 = nn.BatchNorm1d(40)\n",
    "        self.drop4 = nn.Dropout(0.25)\n",
    "\n",
    "        self.fc5 = nn.Linear(40, output_size)\n",
    "        \n",
    "        self.relu = nn.SELU() \n",
    "    def forward(self, x):                            \n",
    "\n",
    "        # layer 1\n",
    "        out = self.fc1(x)\n",
    "        out = self.batch1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.drop1(out)\n",
    "\n",
    "        # layer 2\n",
    "        out = self.fc2(out)\n",
    "        out = self.batch2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.drop2(out)\n",
    "\n",
    "        # layer 3\n",
    "        out = self.fc3(out)\n",
    "        out = self.batch3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.drop3(out)\n",
    "\n",
    "        # layer 4\n",
    "        out = self.fc4(out)\n",
    "        out = self.batch4(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.drop4(out)\n",
    "\n",
    "        out = self.fc5(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e5b6555d-291e-49f8-b8a9-f5cc553c88fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using gpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print('using gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4405b7b5-1b62-4958-8200-ebf482c54a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 4), (10000, 2))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO split into real and imaginary parts\n",
    "X = trnden[140].reshape((10000,4))\n",
    "y = trntimecoeffs[140]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d9bfe151-9741-437d-81c0-7466b0d5c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(X, y, test_size=0.10, random_state=57109, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "39abced8-cf83-425d-aa1d-b0d64766b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datat = torch.from_numpy(train_data)\n",
    "train_labelst = torch.from_numpy(train_labels)\n",
    "test_datat = torch.from_numpy(test_data)\n",
    "test_labelst = torch.from_numpy(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9ce19732-01f8-40e4-8ee4-ee266276d84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 100\n",
    "net = Net(input_size, hidden_size, output_size)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2edd395d-40c7-402c-96a0-e1cf5e5e0362",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datat = train_datat.to(device)\n",
    "train_labelst = train_labelst.to(device)\n",
    "test_datat = test_datat.to(device)\n",
    "test_labelst = test_labelst.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "35d77589-010b-4d49-9cb6-9547af7d1609",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion2 = nn.MSELoss()\n",
    "criterion1 = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adc4409-e1f3-40ad-b362-fcdceb7fff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_94948/122950603.py\u001b[0m(15)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     13 \u001b[0;31m                \u001b[0mbatched_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_datat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m            \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 15 \u001b[0;31m            \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m            \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError: mat1 and mat2 must have the same dtype\n",
      "> \u001b[0;32m/tmp/ipykernel_94948/122950603.py\u001b[0m(15)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     13 \u001b[0;31m                \u001b[0mbatched_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_datat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m            \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 15 \u001b[0;31m            \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m            \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 256\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "        final_score = 0\n",
    "        final_loss = 0\n",
    "        for i in range(0, train_datat.shape[0], batch_size):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if i + batch_size > train_datat.shape[0]:\n",
    "                batched_data = train_datat[i:]\n",
    "            else:\n",
    "                batched_data = train_datat[i: i + batch_size]\n",
    "            import pdb; pdb.set_trace()\n",
    "            outputs = net(batched_data)\n",
    "           \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_score = len(predicted[predicted == train_labelst[i: i + batch_size]]) / len(train_labelst[i: i + batch_size])\n",
    "            \n",
    "            out = net(test_datat.cfloat())\n",
    "            _, predictedt = torch.max(out.data, 1)\n",
    "            test_score = len(predictedt[predictedt == test_labelst]) / len(test_labelst)\n",
    "            \n",
    "            final_score = test_score\n",
    "            loss =  criterion(outputs, train_labelst[i: i + batch_size])\n",
    "            final_loss = loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        losses.append(loss)\n",
    "        train_acc.append(train_score)\n",
    "        test_acc.append(test_score)\n",
    "        \n",
    "        print('Epoch: {}/{}.............'.format(epoch, num_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "print('======================================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eceb292-6e7e-463d-83af-672bd1de3b04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.9.0",
   "language": "python",
   "name": "tensorflow-2.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
