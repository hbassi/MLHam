{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b284159-7f80-4d9f-90e7-975fba6066ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, lax, vmap, jacobian\n",
    "import jax.scipy.linalg as jsl\n",
    "\n",
    "import jax\n",
    "\n",
    "import numpy as np\n",
    "from read_traj_v2 import *\n",
    "\n",
    "import scipy.optimize\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79a0da5f-028b-4f4c-be12-7ca07585cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f652cf0-1006-4ab2-9b0e-3b18176f72ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d65dfd65-0527-4b63-9fd6-1d1e188f0c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\treading from \"./correctdata/ke+en+overlap+ee_twoe+dip_casscf22_heh+_sto-3g.npz\"\n",
      "\n",
      "can only concatenate str (not \"NoneType\") to str\n",
      "True is not in list\n"
     ]
    }
   ],
   "source": [
    "mol = 'heh+'\n",
    "basis = 'sto-3g'\n",
    "init = 'hf'\n",
    "td = 'rt-tdexx'\n",
    "\n",
    "dt = 0.08268/10\n",
    "\n",
    "inpath = './correctdata'\n",
    "inpath2 = './mydata/'\n",
    "outpath = './'\n",
    "saved_model_dir = './models/'\n",
    "\n",
    "trnfrq = jnp.array(np.load('./tdcis_data/tdcis_trnfreq_dt0.008268.npz'))\n",
    "trnamp = jnp.array(np.load('./tdcis_data/tdcis_trnamp_dt0.008268.npz'))\n",
    "trntme = jnp.array(np.load('./tdcis_data/tdcis_trntme_dt0.008268.npz'))\n",
    "# load important static matrices\n",
    "a = traj_data(inpath, mol, basis, init, td, '001',\n",
    "                init_cond_file=f'ke+en+overlap+ee_twoe+dip_casscf22_{mol}_{basis}.npz',\n",
    "                )\n",
    "a.assign_init_data()\n",
    "drc = a.drc\n",
    "xmat, didat, kinmat, enmat = a.xmat, a.didat, a.kinmat, a.enmat\n",
    "X = xmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eac6183-de7c-4322-ae9b-e928ee129e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301, 10000, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "trnden = np.array(np.load('./tdcis_data/tdcis_dt0.0082680.npz'))\n",
    "print(trnden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "871387af-8a1e-431c-a25e-657f12b6e36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 10000, 2)\n"
     ]
    }
   ],
   "source": [
    "trntimecoeffs = np.array(np.load('./tdcis_data/time_coeffs_tdcis_dt0.008268.npz'))\n",
    "print(trntimecoeffs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d7e342a-c268-421c-ab11-cde905996c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "input_size = 4\n",
    "output_size = 4\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    \n",
    "        # layer 1\n",
    "        self.fc1 = nn.Linear(input_size, 100) \n",
    "        self.batch1 = nn.BatchNorm1d(100)\n",
    "        self.drop1 = nn.Dropout(0.25)\n",
    "\n",
    "        # layer 2\n",
    "        self.fc2 = nn.Linear(100, 80)\n",
    "        self.batch2 = nn.BatchNorm1d(80)\n",
    "        self.drop2 = nn.Dropout(0.25)\n",
    "\n",
    "        # layer 3\n",
    "        self.fc3 = nn.Linear(80, 60)\n",
    "        self.batch3 = nn.BatchNorm1d(60)\n",
    "        self.drop3 = nn.Dropout(0.25)\n",
    "\n",
    "        # layer 4\n",
    "        self.fc4 = nn.Linear(60, 40)\n",
    "        self.batch4 = nn.BatchNorm1d(40)\n",
    "        self.drop4 = nn.Dropout(0.25)\n",
    "\n",
    "        self.fc5 = nn.Linear(40, output_size)\n",
    "        \n",
    "        self.selu = nn.SELU() \n",
    "        self.sm = nn.Softmax(dim=1)\n",
    "    def forward(self, x):                            \n",
    "\n",
    "        # layer 1\n",
    "        out = self.fc1(x)\n",
    "        out = self.batch1(out)\n",
    "        out = self.selu(out)\n",
    "        out = self.drop1(out)\n",
    "\n",
    "        # layer 2\n",
    "        out = self.fc2(out)\n",
    "        out = self.batch2(out)\n",
    "        out = self.selu(out)\n",
    "        out = self.drop2(out)\n",
    "\n",
    "        # layer 3\n",
    "        out = self.fc3(out)\n",
    "        out = self.batch3(out)\n",
    "        out = self.selu(out)\n",
    "        out = self.drop3(out)\n",
    "\n",
    "        # layer 4\n",
    "        out = self.fc4(out)\n",
    "        out = self.batch4(out)\n",
    "        out = self.selu(out)\n",
    "        out = self.drop4(out)\n",
    "\n",
    "        out = self.fc5(out)\n",
    "        out = self.sm(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5b6555d-291e-49f8-b8a9-f5cc553c88fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using gpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print('using gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4405b7b5-1b62-4958-8200-ebf482c54a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 4), (10000, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO split into real and imaginary parts\n",
    "X = trnden[140].reshape((10000,4))\n",
    "y = trntimecoeffs[140]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9dabb1e-60e9-4c17-86f9-4c4313b2c544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10477089+0.00000000e+00j, 0.30625791+0.00000000e+00j,\n",
       "        0.30625791+0.00000000e+00j, 0.89522938+0.00000000e+00j],\n",
       "       [0.10477089+0.00000000e+00j, 0.30625791+0.00000000e+00j,\n",
       "        0.30625791+0.00000000e+00j, 0.89522938+0.00000000e+00j],\n",
       "       [0.10477089+6.78269230e-24j, 0.30625792-1.90978295e-06j,\n",
       "        0.30625792+1.90978295e-06j, 0.89522937-1.05200500e-23j],\n",
       "       ...,\n",
       "       [0.11820466-2.04482806e-18j, 0.31036451-8.85466911e-02j,\n",
       "        0.31036451+8.85466911e-02j, 0.88179556-2.15445319e-18j],\n",
       "       [0.1186949 -1.17808971e-18j, 0.31099718-8.84392895e-02j,\n",
       "        0.31099718+8.84392895e-02j, 0.88130531+1.26516016e-18j],\n",
       "       [0.11918453+1.91714554e-18j, 0.31162905-8.83246533e-02j,\n",
       "        0.31162905+8.83246533e-02j, 0.88081568-7.48351412e-18j]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d9d61fd-737a-43b6-b8d1-f548947796b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "newX = np.zeros(X.shape)\n",
    "for i in range(X.shape[0]):\n",
    "    newX[i] = np.array([X[i][0].real, X[i][1].real, X[i][1].imag, X[i][3].real])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "000df7c9-e6d2-4e6a-8b3a-8a180899a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "newy = np.zeros((y.shape[0],4))\n",
    "for i in range(y.shape[0]):\n",
    "    newy[i] = np.array([y[i][0].real, y[i][0].imag, y[i][1].real, y[i][1].imag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abea5d94-de9c-48a0-a25d-488b9caddf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = newX\n",
    "y = newy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9bfe151-9741-437d-81c0-7466b0d5c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(X, y, test_size=0.10, random_state=57109, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39abced8-cf83-425d-aa1d-b0d64766b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datat = torch.from_numpy(train_data)\n",
    "train_labelst = torch.from_numpy(train_labels)\n",
    "test_datat = torch.from_numpy(test_data)\n",
    "test_labelst = torch.from_numpy(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ce19732-01f8-40e4-8ee4-ee266276d84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 100\n",
    "net = Net(input_size, hidden_size, output_size)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2edd395d-40c7-402c-96a0-e1cf5e5e0362",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datat = train_datat.to(device)\n",
    "train_labelst = train_labelst.to(device)\n",
    "test_datat = test_datat.to(device)\n",
    "test_labelst = test_labelst.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35d77589-010b-4d49-9cb6-9547af7d1609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import mse_loss\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7adc4409-e1f3-40ad-b362-fcdceb7fff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18334/3876127444.py:58: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.sm(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100/1000............. Loss: 0.0031\n",
      "Epoch: 200/1000............. Loss: 0.0031\n",
      "Epoch: 300/1000............. Loss: 0.0031\n",
      "Epoch: 400/1000............. Loss: 0.0031\n",
      "Epoch: 500/1000............. Loss: 0.0031\n",
      "Epoch: 600/1000............. Loss: 0.0031\n",
      "Epoch: 700/1000............. Loss: 0.0031\n",
      "Epoch: 800/1000............. Loss: 0.0031\n",
      "Epoch: 900/1000............. Loss: 0.0031\n",
      "Epoch: 1000/1000............. Loss: 0.0031\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "batch_size = 256\n",
    "losses = []\n",
    "train_acc = []\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "        final_loss = 0\n",
    "        for i in range(0, train_datat.shape[0], batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            if i + batch_size > train_datat.shape[0]:\n",
    "                batched_data = train_datat[i:]\n",
    "            else:\n",
    "                batched_data = train_datat[i: i + batch_size]\n",
    "            outputs = net(batched_data)\n",
    "            loss =  mse_loss(outputs, train_labelst[i: i + batch_size])\n",
    "            final_loss = loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        losses.append(loss)\n",
    "        train_acc.append(train_score) \n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch: {}/{}.............'.format(epoch, num_epochs), end=' ')\n",
    "            print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2eceb292-6e7e-463d-83af-672bd1de3b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18334/3876127444.py:58: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.sm(out)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9.9796e-01, 5.3200e-39, 1.9804e-03, 6.1775e-05],\n",
       "        [9.9969e-01, 2.4524e-37, 2.0859e-04, 1.0014e-04],\n",
       "        [9.9926e-01, 2.3882e-31, 2.8194e-04, 4.5955e-04],\n",
       "        ...,\n",
       "        [9.9948e-01, 1.6088e-37, 5.1086e-04, 1.2386e-05],\n",
       "        [9.9891e-01, 2.2842e-37, 1.0915e-03, 2.8661e-06],\n",
       "        [9.9921e-01, 5.5645e-36, 7.4707e-04, 4.0469e-05]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(torch.from_numpy(newX).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba11839d-0990-4b25-9a6c-de2e8d0cf898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0000000e+00,  3.4200000e-06, -1.0000000e-08, -2.7000000e-06],\n",
       "       [ 1.0000000e+00,  1.0270000e-05, -6.0000000e-08, -8.1000000e-06],\n",
       "       [ 1.0000000e+00,  2.0530000e-05, -1.7000000e-07, -1.6200000e-05],\n",
       "       ...,\n",
       "       [ 9.9182448e-01,  8.7885200e-03, -1.7524880e-02, -1.2609455e-01],\n",
       "       [ 9.9182448e-01,  8.7885200e-03, -1.8664610e-02, -1.2593089e-01],\n",
       "       [ 9.9182448e-01,  8.7885200e-03, -1.9802810e-02, -1.2575693e-01]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f86d7cc-69f1-47ad-8224-8f596f34e0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18334/3876127444.py:58: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.sm(out)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.93615856811218"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = net(torch.from_numpy(newX).to(device)).cpu()\n",
    "y = newy\n",
    "np.linalg.norm((x.detach().numpy()-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f9bb55-910c-4db1-b29e-821042fedef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.9.0",
   "language": "python",
   "name": "tensorflow-2.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
