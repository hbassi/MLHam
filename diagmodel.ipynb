{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b264029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, grad, jacobian, lax, vmap, pmap\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.integrate as si\n",
    "import scipy.optimize as so\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e77fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given time series observations, our goal here is to find f(x)\n",
    "# such that the observations can be predicted using the ODE\n",
    "# dx/dt = \\dot{x} = f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88caecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# typical supervised learning task\n",
    "# you have a lot of (x, y) pairs\n",
    "# you want a function y = f(x)\n",
    "# our problem is different, we never directly observe the thing we're trying to learn (which is f(x))1q\n",
    "dilfac = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f9b2eb4-655f-4be7-8da1-81010262b29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 20000, 2, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltraj = np.load('heh+_training_data.npz')\n",
    "alltraj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f34fd74-a7d0-45b5-84fb-a8d59a9331c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 400, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatten density matrices into a vector and reshape to be in form \n",
    "trajs = []\n",
    "for i in range(alltraj.shape[0]):\n",
    "    traj = alltraj[i]\n",
    "    steps  = []\n",
    "    for j in range(400):\n",
    "        vec = np.zeros((2,),dtype=np.complex128)\n",
    "        denmat = traj[j]\n",
    "        v1 = denmat[0][0]\n",
    "        v2 = denmat[1][1]\n",
    "        vec[0] = v1\n",
    "        vec[1] = v2\n",
    "        steps.append(vec)\n",
    "    trajs.append(steps)\n",
    "trajs = np.array(trajs)\n",
    "trajs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd320aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8770\n"
     ]
    }
   ],
   "source": [
    "# now pretend we don't know the vector field but we want to learn it\n",
    "# set up a neural network model for f\n",
    "nlayers = 4\n",
    "\n",
    "# units per hidden layer\n",
    "uphl = 64\n",
    "\n",
    "# dimension of vector field\n",
    "vfd = 2\n",
    "\n",
    "# set up neural network parameters\n",
    "layerwidths = [2*vfd,uphl,uphl,uphl,vfd]\n",
    "numparams = 0\n",
    "numweights = 0\n",
    "numbiases = 0\n",
    "for j in range(nlayers):\n",
    "    numparams += layerwidths[j]*layerwidths[j+1] + layerwidths[j+1]\n",
    "    numweights += layerwidths[j]*layerwidths[j+1]\n",
    "    numbiases += layerwidths[j+1]\n",
    "\n",
    "# print out total number of parameters\n",
    "print(numparams)\n",
    "\n",
    "# definition of actual neural network function\n",
    "def neuralf(x, theta):\n",
    "    filt = []\n",
    "    si = 0\n",
    "    ei = layerwidths[0]*layerwidths[1]\n",
    "    filt.append( theta[si:ei].reshape((layerwidths[0],layerwidths[1])) )\n",
    "    si += layerwidths[0]*layerwidths[1]\n",
    "    ei += layerwidths[1]*layerwidths[2]\n",
    "    filt.append( theta[si:ei].reshape((layerwidths[1],layerwidths[2])) )\n",
    "    si += layerwidths[1]*layerwidths[2]\n",
    "    ei += layerwidths[2]*layerwidths[3]\n",
    "    filt.append( theta[si:ei].reshape((layerwidths[2],layerwidths[3])) )\n",
    "    si += layerwidths[2]*layerwidths[3]\n",
    "    ei += layerwidths[3]*layerwidths[4]\n",
    "    filt.append( theta[si:ei].reshape((layerwidths[3],layerwidths[4])) )\n",
    "    bias = []\n",
    "    si += layerwidths[3]*layerwidths[4]\n",
    "    ei += layerwidths[1]\n",
    "    bias.append( theta[si:ei] )\n",
    "    si += layerwidths[1]\n",
    "    ei += layerwidths[2]\n",
    "    bias.append( theta[si:ei] )\n",
    "    si += layerwidths[2]\n",
    "    ei += layerwidths[3]\n",
    "    bias.append( theta[si:ei] )\n",
    "    si += layerwidths[3]\n",
    "    ei += layerwidths[4]\n",
    "    bias.append( theta[si:ei] )\n",
    "    inplyr = jnp.concatenate([x.real,x.imag])\n",
    "    h1 = jax.nn.selu( inplyr @ filt[0] + bias[0] )\n",
    "    h2 = jax.nn.selu( h1 @ filt[1] + bias[1] )\n",
    "    h3 = jax.nn.selu( h2 @ filt[2] + bias[2] )\n",
    "    h4 = h3 @ filt[3] + bias[3]\n",
    "    return h4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32cb5d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.experimental import ode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c17b04e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 400, 2)\n"
     ]
    }
   ],
   "source": [
    "# move training data from NumPy to JAX\n",
    "jalltraj = jnp.array(trajs)\n",
    "print(jalltraj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deaf90b1-3ef3-40c9-b030-ae97b2e877ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "numsteps = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83e43776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define JAX function to compute one predicted trajectory\n",
    "def predtraj(y0, theta):\n",
    "    def rhsfunc(y, t):\n",
    "        return neuralf(y, theta)\n",
    "    \n",
    "    intdt = 0.08268/dilfac\n",
    "    intnpts = (numsteps-1)*dilfac + 1\n",
    "    inttint = np.arange(intnpts)*intdt\n",
    "    return ode.odeint(rhsfunc, y0, inttint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9fb89a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now parallelize the above function to handle many initial conditions but one theta\n",
    "vpredtraj = vmap(predtraj, in_axes=(0, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33e3bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now define loss (or objective function)\n",
    "def obj(y, theta):\n",
    "    # compute all predicted trajectories for fixed theta\n",
    "    predfine = predtraj(y[0,:], theta)\n",
    "    pred = predfine[::dilfac, :]\n",
    "    # now compute mean squared errors between predictions and training data\n",
    "    return jnp.mean(jnp.square(pred - y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6b0df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use JAX to compile objective function\n",
    "jobj = jit(obj)\n",
    "\n",
    "# use JAX to compute gradient and compile it\n",
    "jgradobj = jit(grad(obj,1,holomorphic=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6143c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdx = jacobian(neuralf, 0, holomorphic=True)\n",
    "dfdtheta = jacobian(neuralf, 1, holomorphic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50935476",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdfdtheta = vmap(dfdtheta, in_axes=(0,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0f66f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjoint method to compute gradient of objective function\n",
    "# here y stands for one trajectory of observations, of shape (numsteps, 2)\n",
    "def newlagwithgrad(y, theta):\n",
    "    intdt = 0.08268/dilfac\n",
    "    intnpts = (numsteps-1)*dilfac + 1\n",
    "    inttint = np.arange(intnpts)*intdt\n",
    "    \n",
    "    # solve forward problem and compute residual\n",
    "    def rhsfunc(y, t):\n",
    "        return neuralf(y, theta)\n",
    "    \n",
    "    xfine = ode.odeint(rhsfunc, y[0,:], inttint)\n",
    "    \n",
    "    x = xfine[::dilfac,:]\n",
    "    resid = 2*(x - y)\n",
    "    \n",
    "    # compute and save loss for later\n",
    "    obj = jnp.mean(jnp.square(resid))\n",
    "    \n",
    "    # trapezoid rule quadrature weights\n",
    "    w = jnp.concatenate([jnp.array([0.5]),jnp.ones(intnpts-2),jnp.array([0.5])])\n",
    "    \n",
    "    # backward-in-time loop body\n",
    "    # Heun's method backward in time\n",
    "    inth = -intdt\n",
    "    \n",
    "    def bodylamb(j, lambmfine):\n",
    "       \n",
    "        #import pdb; pdb.set_trace()\n",
    "        feval1 = -lambmfine[intnpts-j, :] @ dfdx(xfine[intnpts-j, :], theta.astype(np.complex128)) #@ dfdy(xfine[intnpts-j, :].real,xfine[intnpts-j, :].imag, theta)\n",
    "        lambtilde = lambmfine[intnpts-j, :] + inth*feval1\n",
    "        feval2 = -lambtilde @ dfdx(xfine[intnpts-j-1, :], theta.astype(np.complex128)) #@ dfdy(xfine[intnpts-j-1,:].real ,xfine[intnpts-j-1, :].imag , theta)\n",
    "        prevlamb = lambmfine[intnpts-j, :] + (inth/2.0)*(feval1 + feval2)\n",
    "        prevlamb += ((intnpts-j-1) % dilfac == 0) * resid[(intnpts-j-1)//dilfac, :]\n",
    "        return lambmfine.at[intnpts-j-1].set( prevlamb )\n",
    "    \n",
    "    # loop initialization\n",
    "    lambmat = jnp.concatenate([ jnp.zeros((intnpts-1, vfd)), resid[[numsteps-1],:] ])\n",
    "    \n",
    "    # actually loop\n",
    "    lambout = lax.fori_loop(1, intnpts, bodylamb, lambmat)\n",
    "    \n",
    "    # straight out of the notes\n",
    "    allg = vdfdtheta(xfine, theta.astype(np.complex128))\n",
    "    gradtheta = intdt*jnp.einsum('ij,ijk,i->k',lambout,allg,w)\n",
    "    gradtheta *= (1.0/(2*numsteps))\n",
    "    return obj, gradtheta\n",
    "\n",
    "jnlwg = jit(newlagwithgrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "587f1455",
   "metadata": {},
   "outputs": [],
   "source": [
    "jnewlagwithgrad = jit(newlagwithgrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4a30b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random initializer\n",
    "def glorotinit():\n",
    "    theta = []\n",
    "    sd = np.sqrt(2.0 / (layerwidths[0]+layerwidths[1]))\n",
    "    theta.append( np.random.normal(size=layerwidths[0]*layerwidths[1])*sd )\n",
    "    sd = np.sqrt(2.0 / (layerwidths[1]+layerwidths[2]))\n",
    "    theta.append( np.random.normal(size=layerwidths[1]*layerwidths[2])*sd )\n",
    "    sd = np.sqrt(2.0 / (layerwidths[2]+layerwidths[3]))\n",
    "    theta.append( np.random.normal(size=layerwidths[2]*layerwidths[3])*sd )\n",
    "    sd = np.sqrt(2.0 / (layerwidths[3]+layerwidths[4]))\n",
    "    theta.append( np.random.normal(size=layerwidths[3]*layerwidths[4])*sd )\n",
    "    theta.append( np.zeros(numbiases) )\n",
    "    theta = np.concatenate(theta)\n",
    "    return theta\n",
    "\n",
    "theta0 = glorotinit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d3d621-a616-455d-86cb-1fe8c8bbc64c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ef171129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0673370361328125\n",
      "3.8646726608276367\n",
      "19.78648017321262\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "myobj, mygrad = jnewlagwithgrad(jalltraj[0], theta0)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "\n",
    "start = time.time()\n",
    "jaxobj = jobj(jalltraj[0], theta0)\n",
    "jaxgrad = jgradobj(jalltraj[0], theta0.astype(np.complex128))\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "\n",
    "print(jnp.mean(jnp.abs(jaxgrad-mygrad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "29c81467",
   "metadata": {},
   "outputs": [],
   "source": [
    "jvnewlagwithgrad = jit(vmap(newlagwithgrad, in_axes=(0,None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f0a1185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debugging purposes\n",
    "#tobj, tgrad = jvnewlagwithgrad(jalltraj, theta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc38bc75-e87f-4036-b688-81469de0003d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5ec34f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap functions so that we can use them in standard NumPy/SciPy\n",
    "def objgradSP(theta):\n",
    "    jaxobj, jaxgrads = jvnewlagwithgrad(jalltraj, theta)\n",
    "    return jnp.mean(jaxobj).item(), np.array(jnp.mean(jaxgrads,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7bd665ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'complex' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# trust region optimizer with SR1 update\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mso\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjgradSP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtheta0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrust-constr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mhess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mso\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSR1\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxtol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mverbose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# L-BFGS-B optimizer\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# res = so.minimize(fun=objSP, jac=gradSP, x0=theta0, method='L-BFGS-B',\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#                   options={'gtol': 1e-8, 'ftol':1e-8, 'iprint':1})\u001b[39;00m\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/scipy/optimize/_minimize.py:711\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    708\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_slsqp(fun, x0, args, jac, bounds,\n\u001b[1;32m    709\u001b[0m                           constraints, callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust-constr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 711\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_trustregion_constr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhessp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdogleg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    715\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_dogleg(fun, x0, args, jac, hess,\n\u001b[1;32m    716\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/scipy/optimize/_trustregion_constr/minimize_trustregion_constr.py:332\u001b[0m, in \u001b[0;36m_minimize_trustregion_constr\u001b[0;34m(fun, x0, args, grad, hess, hessp, bounds, constraints, xtol, gtol, barrier_tol, sparse_jacobian, callback, maxiter, verbose, finite_diff_rel_step, initial_constr_penalty, initial_tr_radius, initial_barrier_parameter, initial_barrier_tolerance, factorization_method, disp)\u001b[0m\n\u001b[1;32m    329\u001b[0m     finite_diff_bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# Define Objective Function\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m objective \u001b[38;5;241m=\u001b[39m \u001b[43mScalarFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinite_diff_bounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# Put constraints in list format when needed.\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(constraints, (NonlinearConstraint, LinearConstraint)):\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:158\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl \u001b[38;5;241m=\u001b[39m update_fun\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# Gradient evaluation\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(grad):\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:148\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    144\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe user-provided objective function \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust return a scalar value.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lowest_f\u001b[49m:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_x \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_f \u001b[38;5;241m=\u001b[39m fx\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'complex' and 'float'"
     ]
    }
   ],
   "source": [
    "# trust region optimizer with SR1 update\n",
    "res = so.minimize(fun=objgradSP, jac=True, x0=theta0, method='trust-constr', \n",
    "                  hess=so.SR1(), options={'gtol': 1e-3, 'xtol': 1e-3, 'verbose': 2})\n",
    "\n",
    "# L-BFGS-B optimizer\n",
    "# res = so.minimize(fun=objSP, jac=gradSP, x0=theta0, method='L-BFGS-B',\n",
    "#                   options={'gtol': 1e-8, 'ftol':1e-8, 'iprint':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dceac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "allpreds = vpredtraj(jalltraj[:,0,:], jnp.array(res.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbb5ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "allpreds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2fd042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a grid of initial conditions, generate trajectories\n",
    "# this is a phase portrait of the LEARNED DYNAMICAL SYSTEM\n",
    "plt.figure(figsize=(10,6))\n",
    "for i in range(allpreds.shape[0]):\n",
    "    plt.plot(allpreds[i,:,0],allpreds[i,:,1])\n",
    "\n",
    "plt.xlim([-2*xL,2*xL])\n",
    "plt.ylim([-1.5*xL,1.5*xL])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafda366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a phase portrait of the GROUND TRUTH DYNAMICAL SYSTEM\n",
    "plt.figure(figsize=(10,6))\n",
    "for i in range(allpreds.shape[0]):\n",
    "    plt.plot(alltraj[i,0,:],alltraj[i,1,:])\n",
    "\n",
    "plt.xlim([-2*xL,2*xL])\n",
    "plt.ylim([-1.5*xL,1.5*xL])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec782f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.9.0",
   "language": "python",
   "name": "tensorflow-2.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
